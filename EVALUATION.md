# Evaluation policy

The homeworks are evaluated respect to these perspectives:

* [__P1__]: Description of your work
* [__P2__]: Quality in terms of readability and efficiency of code
* [__P3__]: Correctness of the results

Specifically, you will assign a score between 1 and 5 to each of these aspects.

### TAs reviews
The TAs will evaluate all the homeworks.

### Peer evaluation
* For each homework, each student reviews the assignment of 1 group
* Your group will get 3 reviews + 1 (TAs)

The homework you should review will be communicated through Slack. Once you have completed your review, you will submit it through a form where you will be ask to tell us the score of the group for each section and provide explanations about your choices.

Since the way which you do the Peer evaluation __will be part__ of you final grade, here some example of good reviews:

__Positive__

> [__P1__]: Comments are really clear and still manage to be short.

> [__P2__]: Code is really well written: coincise and efficient (see the matching names function as an example, really smart and short)

> [__P3__]: Results obtained are clear, well illustrated with very communicative and effective plots.

__Negative__
>[__P1__]:  The textual description for the two first two tasks is minimal, but it describes properly the problem at hand,  for those I would hand in a 4.5,  but there's barely any comments for the third task, there's commented code left in the modules and there's even a TODO that's been left in there.  It is likely one of the member that didn't finish his task properly, but it is he job of the team to at least proofread the final version...

>[__P2__]:  For the code quality, utilization of libraries is done throughout and the code is concise in what it does. One annoyance  is the fact that head() or tail() wasn't used and the outputs are often longer than what they could be to show the result format.

>[__P3__]:  For the results, first task there's a clear error with the number of new cases in liberia for the last period... passing from ~2 new cases a month to ~2k should raise red flags. At least some explanation of why they kept it, especially in a data wrangling task. In the task two, they didn't re-index, they didn't split the scientific classification string or even clean it, it is clear that they went with the solution with the minimal possible effort. In the third task, it is hard to know exactly what was done ineach cases because of a lack of comments, but the result seem good overall.

Examples of bad reviews:
> Good job
> Something is missing

The overall review of the homework should contain 2 positive and 2 negative aspects of the assignment you are evaluating.

